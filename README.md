# 超小参数推理模型复现项目 (Project Log: Reproducing Ultra-Small Inference Models)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## 项目简介

本项目旨在完整记录从 2025 年 1 月以来，我个人从零开始复现一个高效、超小参数规模推理模型的技术历程。众所周知，将多项前沿工作整合并打造出工业级水准的模型是一项极具挑战性的任务。这份文档不仅是我的开发日志，更是对我在模型架构、分词器选型、训练策略等方面踩过的坑、获得的经验以及最终技术选型的深度总结与思考，希望能为同样走在这条路上的开发者提供一些参考。

## 目录

- [核心理念与技术选型](#核心理念与技术选型)
  - [1. 架构选择：拥抱主流，而非闭门造车](#1-架构选择拥抱主流而非闭门造车)
  - [2. 分词器选型：相信“规模定律”的力量](#2-分词器选型相信规模定律的力量)
  - [3. MoE 架构：资源有限下的性能权衡](#3-moe-架构资源有限下的性能权衡)
  - [4. 语料与训练策略：模型的燃料](#4-语料与训练策略模型的燃料)
- [项目进展日志](#项目进展日志)
- [当前挑战与思考](#当前挑战与思考)
  - [关于强化学习的瓶颈](#关于强化学习的瓶颈)
  - [关于模型输出“乱码”的分析](#关于模型输出乱码的分析)
- [未来计划](#未来计划)
- [如何贡献](#如何贡献)
- [许可证](#许可证)

## 核心理念与技术选型

早在 OpenAI 公开其 O1 模型时，我就已开始探索小型推理模型的构建。期间经历了多次失败，最终决定摒弃所有历史包袱，从零开始这一征途。以下是我在此过程中沉淀下的核心思考。

### 1. 架构选择：拥抱主流，而非闭门造车

在项目初期，我曾尝试构建一个全新的、自定义的 GPT 架构。然而，纵观当前众多成功的开源模型，一个清晰的共识是：**模型的最终效果更多取决于语料的质量和训练的深度，而非架构的标新立异。**

我强烈不建议任何尝试构建 LLM 的个人或小团队走“自研架构”这条路。原因如下：

*   **生态兼容性是生命线**：一个无法被 `transformers` 的 `AutoModelForCausalLM` 加载，或不兼容主流分词器标准的模型，无异于在自己的小圈子里自娱自乐，极大地限制了其应用和发展。
*   **工程成本巨大**：为了让自定义架构兼容主流的训练框架（如 DeepSpeed, FSDP）、强化学习框架（如 TRL, RLHF-V），你需要付出远超模型研发本身的巨大工程努力。
*   **行业标准的重要性**：正如芯片设计者不会为了创新而抛弃行业标准一样，模型的实用性远比其结构上的“独创性”重要。放弃兼容性，就是放弃了被更广泛社区验证和使用的可能性。

**结论**：选择一个经过验证的主流架构（如 Llama, Mistral, Qwen, DeepSeek 等）作为基座，能让您将精力聚焦在数据、训练和对齐等更有价值的环节。

### 2. 分词器选型：相信“规模定律”的力量

分词器是模型与世界交互的窗口，其重要性不言而喻。

*   **早期尝试与失败**：我曾预训练过一个包含约 16,384 个词元、覆盖中英双语的 BPE 分词器。但在后续的预训练中，其性能远未达到预期。
*   **大词表的优势**：消融实验证明，**分词器的词表大小同样存在“规模拓展定律” (Scaling Law)**。虽然像 Qwen (150k+) 或 DeepSeek (100k+) 这样的大型分词器对于纯中英任务看似有些“大材小用”，但它们是巨头们利用海量 GPU 资源在极其广泛和多样化的语料上训练得出的最优解。
*   **选择大词表的收益**：
    1.  **提升训练效率**：更大的词表意味着可以用更少的 Token 来表示相同的文本，这直接减少了训练所需的总 Token 数量，从而加速了语料的“消化”过程。
    2.  **优化推理与强化学习**：在推理或强化学习（RL）阶段，模型可以用更精炼的 Token 序列来表达复杂的思想或推理路径，而不是耗费大量 Token 去拼凑浅层的语义，这对提升模型的推理能力至关重要。

**结论**：直接采用或微调一个由大公司发布的高质量、大词表分词器，是性价比最高的选择。

### 3. MoE 架构：资源有限下的性能权衡

在模型架构层面，我最终倾向于采用 **MoE (Mixture of Experts)** 架构。

我大约在 23 年末就开始了对 MoE 的探索，当时 Mistral-8x7B 等模型的成功已经验证了其潜力。选择 MoE 的初衷非常明确：**在有限的计算资源下，最大化模型的性能**。MoE 架构能以一个相对较小的激活参数量（Activated Parameters），实现媲美参数规模大得多的密集型模型（Dense Model）的性能。这对于在我个人设备上进行训练和推理至关重要。

然而，尽管我个人选择了 MoE，但我依然给其他实践者一个忠告：

> **如果你希望从零开始构建一个推理模型，我更推荐你从参数密集的传统架构开始。** 因为它的实现更简单、社区支持更成熟，是构建和调试推理能力的更稳固的起点。MoE 的训练和优化有其独特的复杂性，更适合在有了坚实基础后再去探索。

### 4. 语料与训练策略：模型的燃料

*   **语料选择**: 在语料选择上，我进行了大量调研和测试。目前计划采用 **Ultra-FineWeb** 数据集，它整合了高质量的中文 Fine-Web 和英文 Fine-Web 语料，可在 Hugging Face 上获取。我的下一个模型（DeepSeek-Mini 复现）将基于此语料进行训练。
*   **训练策略**:
    *   我之前训练的 `qwen3moe` 模型，在退火阶段混合了 8:2 的预训练和推理语料。虽然指令微调效果尚可，但模型出现了严重的幻觉（例如，将“太阳东升西落”与日冕层联系起来），表明语料覆盖和训练方式仍有待改进。
    *   单纯的余弦学习率衰减可能不是最优解，后续计划尝试**梯形学习率调度 (Trapezoidal Learning Rate Schedule)**，期待能获得更稳定的收敛效果。
*   **数据需求**: 目前仍在积极寻找高质量的**中文数学和代码数据集**，这是提升模型逻辑推理和代码能力的关键，但相关开源资源相对稀缺。

## 项目进展日志

**2025-01-27**
*   **核心事件**：尝试自行实现 DeepSeek-V3 架构，但训练后发现模型无法转换为 `gguf` 格式，因为其架构未在 `llama.cpp` 中注册。
*   **关键教训**：
    1.  **工程兼容性至上**：自研或修改核心架构需要巨大的工程量来实现与下游生态（如 `llama.cpp`）的兼容，对于小团队或个人而言成本极高。
    2.  **对“乱码”的初步反思**：早期训练的小模型（~50M 参数）输出乱码，起初怀疑是分词器问题，后意识到是模型训练不充分所致。对于 BPE 分词器，模型需要正确预测多个连续 Token 才能拼出一个汉字，这对欠训练的模型来说是高难度任务。

**2025-03-21**
*   **核心事件**：转向使用官方的 DeepSeek-V2 架构进行训练。
*   **关键教训**：在没有足够资源和精力修改官方代码并确保其正确性的情况下，直接使用经过验证的官方实现是更务实的选择。幸运的是，DeepSeek-V3 架构兼容 V2，使得这次的训练经验依然有价值。

**2025-04-01**
*   **核心事件**：训练了一个 `qwen3moe` 模型，并在此过程中发现了之前 DeepSeek 模型训练失败的根本原因。
*   **关键教训**：
    1.  **上下文长度的重要性**：我一直采用上下文截断（Context Truncation）策略，但没有检查预训练语料的实际长度。这导致模型在处理短文本时处于“冗余训练”状态，是导致模型性能畸形的罪魁祸首。
    2.  **分词器词表大小的影响**：Qwen 的分词器（~150k）比 DeepSeek（~100k）大很多。这个差异导致在资源有限的情况下，进行强化学习变得极为困难，甚至无法以 `1024 per 8` 的批次大小启动训练。

**2025-06-07**
*   **工作内容**: 针对 DeepSeek-V3 架构进行适配与优化。
*   **具体操作**:
    1.  修复并完善了 MTP (Multi-head Token Parallelism) 与 `aux_loss` (辅助损失) 模块的实现细节。
    2.  设计了一个两段式训练流程：首先在带有 MTP 和 `aux_loss` 的定制架构上进行训练，训练完成后再将模型权重转换为官方标准形式以实现兼容。
*   **实验设置**: 正在进行基于 `torch.float8_e4m3fn` (8-bit) 精度的模型训练实验，以评估其收敛性和最终性能。
*   **待办**: 预训练测试、预训练后权重转换测试。

## 当前挑战与思考

### 关于强化学习的瓶颈

在对模型进行对齐时，强化学习（RL）阶段遇到了瓶颈，主要表现为两种互斥的现象：

1.  **使用 KL 散度约束**: 模型能够很好地遵循预设的格式（Format Following）来完成数学推理任务，但探索能力严重受限，难以产生更高质量的解。
2.  **不使用 KL 散度约束**: 模型在“学习格式”和“学习推理”之间挣扎，任务难度极大。模型需要先学会格式，再学会推理，整个过程非常不稳定，收敛困难。

查阅相关文献（如 R1-Zero 的报告）后发现，模型在训练初期输出无意义内容（乱码），然后逐渐找回格式的现象并不罕见。这或许是一种语言混合或模型寻找自身表达方式的自然过程。就像人在学习外语时，会不自觉地混合母语和外语，以寻找最高效的表达路径。

### 关于模型输出“乱码”的分析

我目前选取了一个在训练后期开始输出“乱码”的模型进行分析。该模型在指令微调后，格式遵循能力尚可。但在加入了更复杂的推理语料进行后续训练后，开始出现格式崩溃。

我的初步判断是：**指令微调可能带来了过度的“格式惯性”**。当模型在新的、更复杂的推理语料上训练时，它试图挣脱原有指令微调带来的强约束，寻找一种更适合表达复杂逻辑的新形式。这个探索过程就外显为暂时的“乱码”或格式崩溃。这并非简单的语料不匹配问题，而是模型在不同能力维度间进行权衡与适应的体现。

## 未来计划

- [ ] 完成基于 DeepSeek-V3 架构的 8-bit 精度训练实验，并发布性能报告。
- [ ] 整理并开源预训练脚本、配置文件和两段式训练的权重转换代码。
- [ ] 探索在当前模型基础上进行指令微调和人类偏好对齐（如 DPO）的有效方法。
- [ ] 撰写更详细的技术博客，分享 MTP、`aux_loss`、梯形学习率调度等模块的实现心得。

## 如何贡献

本项目目前主要为个人探索日志。但非常欢迎您通过 **Issues** 提出问题、分享见解或提供宝贵建议。如果您对项目的某些部分有独到的想法或改进，也欢迎创建 **Pull Request**。

## 许可证

本项目采用 **MIT 许可证**。

Copyright (c) 2024 YourName

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
