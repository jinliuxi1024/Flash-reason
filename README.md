这是一个早期的项目，总结了我从1月以来复现一个超小参数的推理模型进程
事实上，整合多项工作并抵达工业级水准是一件极其困难的事情，为此我付出了众多努力
早在openai公开o1模型的时候，我当时已经在尝试制作这样的推理模型，但是也有很多的失败经验，最终决定从零开始制作这样的推理模型
在早期，我尝试自己构建一个gpt模型，但是，在目前众多开源模型的架构中，可以看到，模型的架构标新立异并不能改变其本体的好坏
当然可以选择自己构建一个架构，我已经尝试过了，但是是否考虑过兼容主流的架构平台呢，当模型不能被autocausalmodel加载,分词器同理，个人而言也是在自己的小圈子自嗨，为此我并
不推荐任何打算搓llm的人走这一条路，因为需要付出更大努力来兼容主流的训练框架，主流的强化学习框架，搓芯片的人也不会选择抛弃行业标准，放弃实用性来构建自己的芯片，

在分词器上，我在早期自己预训练有一个类似的大约16384大小的词表分词器，囊括中文和英文，但是，在后续的预训练上，我发现其效果并不好，你可以想象，当你使用类似qwen或者deepseek的分词器时
你在预训练分词时可以知道
